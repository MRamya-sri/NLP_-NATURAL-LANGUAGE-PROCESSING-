{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsvuJHXjeoFUR2fCF3uDFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MRamya-sri/NLP_NATURAL-LANGUAGE-PROCESSING-/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. TOKENIZATION**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MLXzdlKFQFD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak8BALXHQIyw",
        "outputId": "397ef6d4-3d4b-4b41-9f0b-4ef2f90b705a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AI = \" Artificial intelligence (AI) refers to technology that enables computers and machines to simulate human intelligence and problem-solving capabilities. It allows them to perform tasks that would otherwise require human intervention or intelligence. Examples of AI applications include digital assistants, GPS guidance, autonomous vehicles, and generative AI tools like OpenAI’s ChatGPT1. AI encompasses fields such as machine learning and deep learning, which involve developing algorithms inspired by human decision-making processes. These algorithms learn from available data and make increasingly accurate predictions over time. There are two main types of AI\""
      ],
      "metadata": {
        "id": "zpVTsh1wQI-r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(AI)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z3FRPdDQJCH",
        "outputId": "f5358db0-38b4-47e1-9e1f-b85ff679d7ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to get tokens need to import word_tokenize"
      ],
      "metadata": {
        "id": "VhIhxIT6StS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "B7-SlYjMSlbG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AI_tokens = word_tokenize(AI)\n",
        "AI_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVWSrVAfSliZ",
        "outputId": "d2c685b3-12f4-438d-eccb-94242023c2fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Artificial',\n",
              " 'intelligence',\n",
              " '(',\n",
              " 'AI',\n",
              " ')',\n",
              " 'refers',\n",
              " 'to',\n",
              " 'technology',\n",
              " 'that',\n",
              " 'enables',\n",
              " 'computers',\n",
              " 'and',\n",
              " 'machines',\n",
              " 'to',\n",
              " 'simulate',\n",
              " 'human',\n",
              " 'intelligence',\n",
              " 'and',\n",
              " 'problem-solving',\n",
              " 'capabilities',\n",
              " '.',\n",
              " 'It',\n",
              " 'allows',\n",
              " 'them',\n",
              " 'to',\n",
              " 'perform',\n",
              " 'tasks',\n",
              " 'that',\n",
              " 'would',\n",
              " 'otherwise',\n",
              " 'require',\n",
              " 'human',\n",
              " 'intervention',\n",
              " 'or',\n",
              " 'intelligence',\n",
              " '.',\n",
              " 'Examples',\n",
              " 'of',\n",
              " 'AI',\n",
              " 'applications',\n",
              " 'include',\n",
              " 'digital',\n",
              " 'assistants',\n",
              " ',',\n",
              " 'GPS',\n",
              " 'guidance',\n",
              " ',',\n",
              " 'autonomous',\n",
              " 'vehicles',\n",
              " ',',\n",
              " 'and',\n",
              " 'generative',\n",
              " 'AI',\n",
              " 'tools',\n",
              " 'like',\n",
              " 'OpenAI',\n",
              " '’',\n",
              " 's',\n",
              " 'ChatGPT1',\n",
              " '.',\n",
              " 'AI',\n",
              " 'encompasses',\n",
              " 'fields',\n",
              " 'such',\n",
              " 'as',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'and',\n",
              " 'deep',\n",
              " 'learning',\n",
              " ',',\n",
              " 'which',\n",
              " 'involve',\n",
              " 'developing',\n",
              " 'algorithms',\n",
              " 'inspired',\n",
              " 'by',\n",
              " 'human',\n",
              " 'decision-making',\n",
              " 'processes',\n",
              " '.',\n",
              " 'These',\n",
              " 'algorithms',\n",
              " 'learn',\n",
              " 'from',\n",
              " 'available',\n",
              " 'data',\n",
              " 'and',\n",
              " 'make',\n",
              " 'increasingly',\n",
              " 'accurate',\n",
              " 'predictions',\n",
              " 'over',\n",
              " 'time',\n",
              " '.',\n",
              " 'There',\n",
              " 'are',\n",
              " 'two',\n",
              " 'main',\n",
              " 'types',\n",
              " 'of',\n",
              " 'AI']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(AI_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_pD2tK0V5v0",
        "outputId": "57b444a2-f985-4bbe-ed4a-a029b1f0695f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "frequency distribution (**FreqDist**) , returns the often number of words count"
      ],
      "metadata": {
        "id": "XC6sT9YOWiin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist(AI_tokens)\n",
        "fdist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpgXIr6GWhKE",
        "outputId": "448b79dd-11cc-4b05-9844-68d92a968f22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'AI': 5, 'and': 5, '.': 5, ',': 4, 'intelligence': 3, 'to': 3, 'human': 3, 'that': 2, 'of': 2, 'learning': 2, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "particular word frequeny"
      ],
      "metadata": {
        "id": "49ZOm1T2YrKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdist['intelligence']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgE3JORLX_A-",
        "outputId": "58758540-0537-4500-b11e-fd0cdcc864d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fdist)  #unique number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rKAQi-_ZRi0",
        "outputId": "aef9ad37-2c3c-4d51-f1d6-9a82cf68d73f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "most common top 10 words"
      ],
      "metadata": {
        "id": "YueCc8VeZfDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdist_top10 = fdist.most_common(10)\n",
        "fdist_top10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-GbIFytZR2C",
        "outputId": "18e97323-e1b8-49a1-bcac-64d4ab1fd270"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AI', 5),\n",
              " ('and', 5),\n",
              " ('.', 5),\n",
              " (',', 4),\n",
              " ('intelligence', 3),\n",
              " ('to', 3),\n",
              " ('human', 3),\n",
              " ('that', 2),\n",
              " ('of', 2),\n",
              " ('learning', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "removing all blankline's\n"
      ],
      "metadata": {
        "id": "5Wzo7UIMaSkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import blankline_tokenize\n",
        "AI_blank = blankline_tokenize(AI)\n",
        "AI_blank"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY5c4tLsaXXv",
        "outputId": "1d0f4ffa-60ba-4ff4-fd8d-8edb736a4517"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Artificial intelligence (AI) refers to technology that enables computers and machines to simulate human intelligence and problem-solving capabilities. It allows them to perform tasks that would otherwise require human intervention or intelligence. Examples of AI applications include digital assistants, GPS guidance, autonomous vehicles, and generative AI tools like OpenAI’s ChatGPT1. AI encompasses fields such as machine learning and deep learning, which involve developing algorithms inspired by human decision-making processes. These algorithms learn from available data and make increasingly accurate predictions over time. There are two main types of AI']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(AI_blank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pk4wz_nbQrO",
        "outputId": "f5e2e184-f7bb-4779-e8c9-975fa515b14c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BIGRAMS, TRIGRAMS, NGRAMS"
      ],
      "metadata": {
        "id": "Vc4AULAjf5j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import bigrams, trigrams, ngrams"
      ],
      "metadata": {
        "id": "FVBsnmEkbZky"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grams = list(nltk.bigrams(AI_tokens))\n",
        "grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTTsq9urgFnH",
        "outputId": "80510658-950b-4fec-ee62-01502e31940e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Artificial', 'intelligence'),\n",
              " ('intelligence', '('),\n",
              " ('(', 'AI'),\n",
              " ('AI', ')'),\n",
              " (')', 'refers'),\n",
              " ('refers', 'to'),\n",
              " ('to', 'technology'),\n",
              " ('technology', 'that'),\n",
              " ('that', 'enables'),\n",
              " ('enables', 'computers'),\n",
              " ('computers', 'and'),\n",
              " ('and', 'machines'),\n",
              " ('machines', 'to'),\n",
              " ('to', 'simulate'),\n",
              " ('simulate', 'human'),\n",
              " ('human', 'intelligence'),\n",
              " ('intelligence', 'and'),\n",
              " ('and', 'problem-solving'),\n",
              " ('problem-solving', 'capabilities'),\n",
              " ('capabilities', '.'),\n",
              " ('.', 'It'),\n",
              " ('It', 'allows'),\n",
              " ('allows', 'them'),\n",
              " ('them', 'to'),\n",
              " ('to', 'perform'),\n",
              " ('perform', 'tasks'),\n",
              " ('tasks', 'that'),\n",
              " ('that', 'would'),\n",
              " ('would', 'otherwise'),\n",
              " ('otherwise', 'require'),\n",
              " ('require', 'human'),\n",
              " ('human', 'intervention'),\n",
              " ('intervention', 'or'),\n",
              " ('or', 'intelligence'),\n",
              " ('intelligence', '.'),\n",
              " ('.', 'Examples'),\n",
              " ('Examples', 'of'),\n",
              " ('of', 'AI'),\n",
              " ('AI', 'applications'),\n",
              " ('applications', 'include'),\n",
              " ('include', 'digital'),\n",
              " ('digital', 'assistants'),\n",
              " ('assistants', ','),\n",
              " (',', 'GPS'),\n",
              " ('GPS', 'guidance'),\n",
              " ('guidance', ','),\n",
              " (',', 'autonomous'),\n",
              " ('autonomous', 'vehicles'),\n",
              " ('vehicles', ','),\n",
              " (',', 'and'),\n",
              " ('and', 'generative'),\n",
              " ('generative', 'AI'),\n",
              " ('AI', 'tools'),\n",
              " ('tools', 'like'),\n",
              " ('like', 'OpenAI'),\n",
              " ('OpenAI', '’'),\n",
              " ('’', 's'),\n",
              " ('s', 'ChatGPT1'),\n",
              " ('ChatGPT1', '.'),\n",
              " ('.', 'AI'),\n",
              " ('AI', 'encompasses'),\n",
              " ('encompasses', 'fields'),\n",
              " ('fields', 'such'),\n",
              " ('such', 'as'),\n",
              " ('as', 'machine'),\n",
              " ('machine', 'learning'),\n",
              " ('learning', 'and'),\n",
              " ('and', 'deep'),\n",
              " ('deep', 'learning'),\n",
              " ('learning', ','),\n",
              " (',', 'which'),\n",
              " ('which', 'involve'),\n",
              " ('involve', 'developing'),\n",
              " ('developing', 'algorithms'),\n",
              " ('algorithms', 'inspired'),\n",
              " ('inspired', 'by'),\n",
              " ('by', 'human'),\n",
              " ('human', 'decision-making'),\n",
              " ('decision-making', 'processes'),\n",
              " ('processes', '.'),\n",
              " ('.', 'These'),\n",
              " ('These', 'algorithms'),\n",
              " ('algorithms', 'learn'),\n",
              " ('learn', 'from'),\n",
              " ('from', 'available'),\n",
              " ('available', 'data'),\n",
              " ('data', 'and'),\n",
              " ('and', 'make'),\n",
              " ('make', 'increasingly'),\n",
              " ('increasingly', 'accurate'),\n",
              " ('accurate', 'predictions'),\n",
              " ('predictions', 'over'),\n",
              " ('over', 'time'),\n",
              " ('time', '.'),\n",
              " ('.', 'There'),\n",
              " ('There', 'are'),\n",
              " ('are', 'two'),\n",
              " ('two', 'main'),\n",
              " ('main', 'types'),\n",
              " ('types', 'of'),\n",
              " ('of', 'AI')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grams1 = list(nltk.trigrams(AI_tokens))\n",
        "grams1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nb6vLIDgUwj",
        "outputId": "243c3e36-f358-447b-c9c6-cce6d52b393f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Artificial', 'intelligence', '('),\n",
              " ('intelligence', '(', 'AI'),\n",
              " ('(', 'AI', ')'),\n",
              " ('AI', ')', 'refers'),\n",
              " (')', 'refers', 'to'),\n",
              " ('refers', 'to', 'technology'),\n",
              " ('to', 'technology', 'that'),\n",
              " ('technology', 'that', 'enables'),\n",
              " ('that', 'enables', 'computers'),\n",
              " ('enables', 'computers', 'and'),\n",
              " ('computers', 'and', 'machines'),\n",
              " ('and', 'machines', 'to'),\n",
              " ('machines', 'to', 'simulate'),\n",
              " ('to', 'simulate', 'human'),\n",
              " ('simulate', 'human', 'intelligence'),\n",
              " ('human', 'intelligence', 'and'),\n",
              " ('intelligence', 'and', 'problem-solving'),\n",
              " ('and', 'problem-solving', 'capabilities'),\n",
              " ('problem-solving', 'capabilities', '.'),\n",
              " ('capabilities', '.', 'It'),\n",
              " ('.', 'It', 'allows'),\n",
              " ('It', 'allows', 'them'),\n",
              " ('allows', 'them', 'to'),\n",
              " ('them', 'to', 'perform'),\n",
              " ('to', 'perform', 'tasks'),\n",
              " ('perform', 'tasks', 'that'),\n",
              " ('tasks', 'that', 'would'),\n",
              " ('that', 'would', 'otherwise'),\n",
              " ('would', 'otherwise', 'require'),\n",
              " ('otherwise', 'require', 'human'),\n",
              " ('require', 'human', 'intervention'),\n",
              " ('human', 'intervention', 'or'),\n",
              " ('intervention', 'or', 'intelligence'),\n",
              " ('or', 'intelligence', '.'),\n",
              " ('intelligence', '.', 'Examples'),\n",
              " ('.', 'Examples', 'of'),\n",
              " ('Examples', 'of', 'AI'),\n",
              " ('of', 'AI', 'applications'),\n",
              " ('AI', 'applications', 'include'),\n",
              " ('applications', 'include', 'digital'),\n",
              " ('include', 'digital', 'assistants'),\n",
              " ('digital', 'assistants', ','),\n",
              " ('assistants', ',', 'GPS'),\n",
              " (',', 'GPS', 'guidance'),\n",
              " ('GPS', 'guidance', ','),\n",
              " ('guidance', ',', 'autonomous'),\n",
              " (',', 'autonomous', 'vehicles'),\n",
              " ('autonomous', 'vehicles', ','),\n",
              " ('vehicles', ',', 'and'),\n",
              " (',', 'and', 'generative'),\n",
              " ('and', 'generative', 'AI'),\n",
              " ('generative', 'AI', 'tools'),\n",
              " ('AI', 'tools', 'like'),\n",
              " ('tools', 'like', 'OpenAI'),\n",
              " ('like', 'OpenAI', '’'),\n",
              " ('OpenAI', '’', 's'),\n",
              " ('’', 's', 'ChatGPT1'),\n",
              " ('s', 'ChatGPT1', '.'),\n",
              " ('ChatGPT1', '.', 'AI'),\n",
              " ('.', 'AI', 'encompasses'),\n",
              " ('AI', 'encompasses', 'fields'),\n",
              " ('encompasses', 'fields', 'such'),\n",
              " ('fields', 'such', 'as'),\n",
              " ('such', 'as', 'machine'),\n",
              " ('as', 'machine', 'learning'),\n",
              " ('machine', 'learning', 'and'),\n",
              " ('learning', 'and', 'deep'),\n",
              " ('and', 'deep', 'learning'),\n",
              " ('deep', 'learning', ','),\n",
              " ('learning', ',', 'which'),\n",
              " (',', 'which', 'involve'),\n",
              " ('which', 'involve', 'developing'),\n",
              " ('involve', 'developing', 'algorithms'),\n",
              " ('developing', 'algorithms', 'inspired'),\n",
              " ('algorithms', 'inspired', 'by'),\n",
              " ('inspired', 'by', 'human'),\n",
              " ('by', 'human', 'decision-making'),\n",
              " ('human', 'decision-making', 'processes'),\n",
              " ('decision-making', 'processes', '.'),\n",
              " ('processes', '.', 'These'),\n",
              " ('.', 'These', 'algorithms'),\n",
              " ('These', 'algorithms', 'learn'),\n",
              " ('algorithms', 'learn', 'from'),\n",
              " ('learn', 'from', 'available'),\n",
              " ('from', 'available', 'data'),\n",
              " ('available', 'data', 'and'),\n",
              " ('data', 'and', 'make'),\n",
              " ('and', 'make', 'increasingly'),\n",
              " ('make', 'increasingly', 'accurate'),\n",
              " ('increasingly', 'accurate', 'predictions'),\n",
              " ('accurate', 'predictions', 'over'),\n",
              " ('predictions', 'over', 'time'),\n",
              " ('over', 'time', '.'),\n",
              " ('time', '.', 'There'),\n",
              " ('.', 'There', 'are'),\n",
              " ('There', 'are', 'two'),\n",
              " ('are', 'two', 'main'),\n",
              " ('two', 'main', 'types'),\n",
              " ('main', 'types', 'of'),\n",
              " ('types', 'of', 'AI')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gram_N = list(nltk.ngrams(AI_tokens, 5))\n",
        "gram_N"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSwWW1qEgdn4",
        "outputId": "8287304f-1740-4691-8565-9cc0dcfb9f3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Artificial', 'intelligence', '(', 'AI', ')'),\n",
              " ('intelligence', '(', 'AI', ')', 'refers'),\n",
              " ('(', 'AI', ')', 'refers', 'to'),\n",
              " ('AI', ')', 'refers', 'to', 'technology'),\n",
              " (')', 'refers', 'to', 'technology', 'that'),\n",
              " ('refers', 'to', 'technology', 'that', 'enables'),\n",
              " ('to', 'technology', 'that', 'enables', 'computers'),\n",
              " ('technology', 'that', 'enables', 'computers', 'and'),\n",
              " ('that', 'enables', 'computers', 'and', 'machines'),\n",
              " ('enables', 'computers', 'and', 'machines', 'to'),\n",
              " ('computers', 'and', 'machines', 'to', 'simulate'),\n",
              " ('and', 'machines', 'to', 'simulate', 'human'),\n",
              " ('machines', 'to', 'simulate', 'human', 'intelligence'),\n",
              " ('to', 'simulate', 'human', 'intelligence', 'and'),\n",
              " ('simulate', 'human', 'intelligence', 'and', 'problem-solving'),\n",
              " ('human', 'intelligence', 'and', 'problem-solving', 'capabilities'),\n",
              " ('intelligence', 'and', 'problem-solving', 'capabilities', '.'),\n",
              " ('and', 'problem-solving', 'capabilities', '.', 'It'),\n",
              " ('problem-solving', 'capabilities', '.', 'It', 'allows'),\n",
              " ('capabilities', '.', 'It', 'allows', 'them'),\n",
              " ('.', 'It', 'allows', 'them', 'to'),\n",
              " ('It', 'allows', 'them', 'to', 'perform'),\n",
              " ('allows', 'them', 'to', 'perform', 'tasks'),\n",
              " ('them', 'to', 'perform', 'tasks', 'that'),\n",
              " ('to', 'perform', 'tasks', 'that', 'would'),\n",
              " ('perform', 'tasks', 'that', 'would', 'otherwise'),\n",
              " ('tasks', 'that', 'would', 'otherwise', 'require'),\n",
              " ('that', 'would', 'otherwise', 'require', 'human'),\n",
              " ('would', 'otherwise', 'require', 'human', 'intervention'),\n",
              " ('otherwise', 'require', 'human', 'intervention', 'or'),\n",
              " ('require', 'human', 'intervention', 'or', 'intelligence'),\n",
              " ('human', 'intervention', 'or', 'intelligence', '.'),\n",
              " ('intervention', 'or', 'intelligence', '.', 'Examples'),\n",
              " ('or', 'intelligence', '.', 'Examples', 'of'),\n",
              " ('intelligence', '.', 'Examples', 'of', 'AI'),\n",
              " ('.', 'Examples', 'of', 'AI', 'applications'),\n",
              " ('Examples', 'of', 'AI', 'applications', 'include'),\n",
              " ('of', 'AI', 'applications', 'include', 'digital'),\n",
              " ('AI', 'applications', 'include', 'digital', 'assistants'),\n",
              " ('applications', 'include', 'digital', 'assistants', ','),\n",
              " ('include', 'digital', 'assistants', ',', 'GPS'),\n",
              " ('digital', 'assistants', ',', 'GPS', 'guidance'),\n",
              " ('assistants', ',', 'GPS', 'guidance', ','),\n",
              " (',', 'GPS', 'guidance', ',', 'autonomous'),\n",
              " ('GPS', 'guidance', ',', 'autonomous', 'vehicles'),\n",
              " ('guidance', ',', 'autonomous', 'vehicles', ','),\n",
              " (',', 'autonomous', 'vehicles', ',', 'and'),\n",
              " ('autonomous', 'vehicles', ',', 'and', 'generative'),\n",
              " ('vehicles', ',', 'and', 'generative', 'AI'),\n",
              " (',', 'and', 'generative', 'AI', 'tools'),\n",
              " ('and', 'generative', 'AI', 'tools', 'like'),\n",
              " ('generative', 'AI', 'tools', 'like', 'OpenAI'),\n",
              " ('AI', 'tools', 'like', 'OpenAI', '’'),\n",
              " ('tools', 'like', 'OpenAI', '’', 's'),\n",
              " ('like', 'OpenAI', '’', 's', 'ChatGPT1'),\n",
              " ('OpenAI', '’', 's', 'ChatGPT1', '.'),\n",
              " ('’', 's', 'ChatGPT1', '.', 'AI'),\n",
              " ('s', 'ChatGPT1', '.', 'AI', 'encompasses'),\n",
              " ('ChatGPT1', '.', 'AI', 'encompasses', 'fields'),\n",
              " ('.', 'AI', 'encompasses', 'fields', 'such'),\n",
              " ('AI', 'encompasses', 'fields', 'such', 'as'),\n",
              " ('encompasses', 'fields', 'such', 'as', 'machine'),\n",
              " ('fields', 'such', 'as', 'machine', 'learning'),\n",
              " ('such', 'as', 'machine', 'learning', 'and'),\n",
              " ('as', 'machine', 'learning', 'and', 'deep'),\n",
              " ('machine', 'learning', 'and', 'deep', 'learning'),\n",
              " ('learning', 'and', 'deep', 'learning', ','),\n",
              " ('and', 'deep', 'learning', ',', 'which'),\n",
              " ('deep', 'learning', ',', 'which', 'involve'),\n",
              " ('learning', ',', 'which', 'involve', 'developing'),\n",
              " (',', 'which', 'involve', 'developing', 'algorithms'),\n",
              " ('which', 'involve', 'developing', 'algorithms', 'inspired'),\n",
              " ('involve', 'developing', 'algorithms', 'inspired', 'by'),\n",
              " ('developing', 'algorithms', 'inspired', 'by', 'human'),\n",
              " ('algorithms', 'inspired', 'by', 'human', 'decision-making'),\n",
              " ('inspired', 'by', 'human', 'decision-making', 'processes'),\n",
              " ('by', 'human', 'decision-making', 'processes', '.'),\n",
              " ('human', 'decision-making', 'processes', '.', 'These'),\n",
              " ('decision-making', 'processes', '.', 'These', 'algorithms'),\n",
              " ('processes', '.', 'These', 'algorithms', 'learn'),\n",
              " ('.', 'These', 'algorithms', 'learn', 'from'),\n",
              " ('These', 'algorithms', 'learn', 'from', 'available'),\n",
              " ('algorithms', 'learn', 'from', 'available', 'data'),\n",
              " ('learn', 'from', 'available', 'data', 'and'),\n",
              " ('from', 'available', 'data', 'and', 'make'),\n",
              " ('available', 'data', 'and', 'make', 'increasingly'),\n",
              " ('data', 'and', 'make', 'increasingly', 'accurate'),\n",
              " ('and', 'make', 'increasingly', 'accurate', 'predictions'),\n",
              " ('make', 'increasingly', 'accurate', 'predictions', 'over'),\n",
              " ('increasingly', 'accurate', 'predictions', 'over', 'time'),\n",
              " ('accurate', 'predictions', 'over', 'time', '.'),\n",
              " ('predictions', 'over', 'time', '.', 'There'),\n",
              " ('over', 'time', '.', 'There', 'are'),\n",
              " ('time', '.', 'There', 'are', 'two'),\n",
              " ('.', 'There', 'are', 'two', 'main'),\n",
              " ('There', 'are', 'two', 'main', 'types'),\n",
              " ('are', 'two', 'main', 'types', 'of'),\n",
              " ('two', 'main', 'types', 'of', 'AI')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. STEMMING**"
      ],
      "metadata": {
        "id": "liJhYhfygpbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()"
      ],
      "metadata": {
        "id": "YHcUx9Obgs1D"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pst.stem(\"having\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bJvC9QKkvLTI",
        "outputId": "a2f528ae-5905-4a77-bb8a-0a19a5cd59fc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "lst = LancasterStemmer()"
      ],
      "metadata": {
        "id": "wsDIwU_WvkSK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst.stem(\"having\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XwnptIlkv1WV",
        "outputId": "493fc9ed-7cd9-4198-a736-7c744e42ed06"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "sst = SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "LxABMMpbv-HT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sst.stem(\"having\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yFhcqTzuwSmC",
        "outputId": "9ce7adba-5dc2-4934-8ad4-b511600ac5a7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. LEMMATIZATION**\n"
      ],
      "metadata": {
        "id": "VP3M-X_BwicF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhElJvjGzHjF",
        "outputId": "464b871c-f14c-4f4c-a2f4-e2a863d0f9d0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wl.lemmatize(\"corpora\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "h5O1LNMyzHv9",
        "outputId": "ec51792e-850b-492a-9e29-ff2fdf6778f7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'corpus'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STOP WORDS REMOVING**\n"
      ],
      "metadata": {
        "id": "AOcCBhQX0e_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjtVqr1zzH35",
        "outputId": "a50ab3d7-c5d9-4e0f-f973-5f43b95fcc9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNNkNZufzH8Z",
        "outputId": "8a55ee48-21a6-40f3-bd4c-8bf7221d20ff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**removing all special characters**"
      ],
      "metadata": {
        "id": "83tj2-Er06_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "G3tm8QTW01V9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = re.compile(r'[-.?!,:;()|0-9]')"
      ],
      "metadata": {
        "id": "StJiyzpc1TlY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ3khpHv1TsF",
        "outputId": "1633b60a-9974-4682-ce78-dd36f99b9be7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "re.compile(r'[-.?!,:;()|0-9]', re.UNICODE)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_punctuation = []\n",
        "for token in AI_tokens:\n",
        "  word = punctuation.sub(\"\", token)\n",
        "  if len(word) > 0:\n",
        "    post_punctuation.append(word)"
      ],
      "metadata": {
        "id": "Nuvre_0v1Txx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj-7jq_Q2Hwd",
        "outputId": "bceea9c6-823f-45d4-9541-50e4f342729e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Artificial',\n",
              " 'intelligence',\n",
              " 'AI',\n",
              " 'refers',\n",
              " 'to',\n",
              " 'technology',\n",
              " 'that',\n",
              " 'enables',\n",
              " 'computers',\n",
              " 'and',\n",
              " 'machines',\n",
              " 'to',\n",
              " 'simulate',\n",
              " 'human',\n",
              " 'intelligence',\n",
              " 'and',\n",
              " 'problemsolving',\n",
              " 'capabilities',\n",
              " 'It',\n",
              " 'allows',\n",
              " 'them',\n",
              " 'to',\n",
              " 'perform',\n",
              " 'tasks',\n",
              " 'that',\n",
              " 'would',\n",
              " 'otherwise',\n",
              " 'require',\n",
              " 'human',\n",
              " 'intervention',\n",
              " 'or',\n",
              " 'intelligence',\n",
              " 'Examples',\n",
              " 'of',\n",
              " 'AI',\n",
              " 'applications',\n",
              " 'include',\n",
              " 'digital',\n",
              " 'assistants',\n",
              " 'GPS',\n",
              " 'guidance',\n",
              " 'autonomous',\n",
              " 'vehicles',\n",
              " 'and',\n",
              " 'generative',\n",
              " 'AI',\n",
              " 'tools',\n",
              " 'like',\n",
              " 'OpenAI',\n",
              " '’',\n",
              " 's',\n",
              " 'ChatGPT',\n",
              " 'AI',\n",
              " 'encompasses',\n",
              " 'fields',\n",
              " 'such',\n",
              " 'as',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'and',\n",
              " 'deep',\n",
              " 'learning',\n",
              " 'which',\n",
              " 'involve',\n",
              " 'developing',\n",
              " 'algorithms',\n",
              " 'inspired',\n",
              " 'by',\n",
              " 'human',\n",
              " 'decisionmaking',\n",
              " 'processes',\n",
              " 'These',\n",
              " 'algorithms',\n",
              " 'learn',\n",
              " 'from',\n",
              " 'available',\n",
              " 'data',\n",
              " 'and',\n",
              " 'make',\n",
              " 'increasingly',\n",
              " 'accurate',\n",
              " 'predictions',\n",
              " 'over',\n",
              " 'time',\n",
              " 'There',\n",
              " 'are',\n",
              " 'two',\n",
              " 'main',\n",
              " 'types',\n",
              " 'of',\n",
              " 'AI']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parts of speech**"
      ],
      "metadata": {
        "id": "q2hx2ynSwoGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"If you want to search for a specific word, this is quite easy. Just know that if any of your documents contain this word or phrase, then all of them will show up at once. To do this, click within the search box after opening the file.\"\n",
        "text_token = word_tokenize(text)\n",
        "text_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YYSpkWs52ov",
        "outputId": "af6467d2-448a-4752-dc71-9ea13250bcd9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['If',\n",
              " 'you',\n",
              " 'want',\n",
              " 'to',\n",
              " 'search',\n",
              " 'for',\n",
              " 'a',\n",
              " 'specific',\n",
              " 'word',\n",
              " ',',\n",
              " 'this',\n",
              " 'is',\n",
              " 'quite',\n",
              " 'easy',\n",
              " '.',\n",
              " 'Just',\n",
              " 'know',\n",
              " 'that',\n",
              " 'if',\n",
              " 'any',\n",
              " 'of',\n",
              " 'your',\n",
              " 'documents',\n",
              " 'contain',\n",
              " 'this',\n",
              " 'word',\n",
              " 'or',\n",
              " 'phrase',\n",
              " ',',\n",
              " 'then',\n",
              " 'all',\n",
              " 'of',\n",
              " 'them',\n",
              " 'will',\n",
              " 'show',\n",
              " 'up',\n",
              " 'at',\n",
              " 'once',\n",
              " '.',\n",
              " 'To',\n",
              " 'do',\n",
              " 'this',\n",
              " ',',\n",
              " 'click',\n",
              " 'within',\n",
              " 'the',\n",
              " 'search',\n",
              " 'box',\n",
              " 'after',\n",
              " 'opening',\n",
              " 'the',\n",
              " 'file',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "for token in text_token:\n",
        "  print(nltk.pos_tag([token]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRqjm54552rS",
        "outputId": "1ae739a3-9425-4834-826e-a7ae84f48cbb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('If', 'IN')]\n",
            "[('you', 'PRP')]\n",
            "[('want', 'NN')]\n",
            "[('to', 'TO')]\n",
            "[('search', 'NN')]\n",
            "[('for', 'IN')]\n",
            "[('a', 'DT')]\n",
            "[('specific', 'JJ')]\n",
            "[('word', 'NN')]\n",
            "[(',', ',')]\n",
            "[('this', 'DT')]\n",
            "[('is', 'VBZ')]\n",
            "[('quite', 'RB')]\n",
            "[('easy', 'JJ')]\n",
            "[('.', '.')]\n",
            "[('Just', 'RB')]\n",
            "[('know', 'VB')]\n",
            "[('that', 'IN')]\n",
            "[('if', 'IN')]\n",
            "[('any', 'DT')]\n",
            "[('of', 'IN')]\n",
            "[('your', 'PRP$')]\n",
            "[('documents', 'NNS')]\n",
            "[('contain', 'NN')]\n",
            "[('this', 'DT')]\n",
            "[('word', 'NN')]\n",
            "[('or', 'CC')]\n",
            "[('phrase', 'NN')]\n",
            "[(',', ',')]\n",
            "[('then', 'RB')]\n",
            "[('all', 'DT')]\n",
            "[('of', 'IN')]\n",
            "[('them', 'PRP')]\n",
            "[('will', 'MD')]\n",
            "[('show', 'NN')]\n",
            "[('up', 'RB')]\n",
            "[('at', 'IN')]\n",
            "[('once', 'RB')]\n",
            "[('.', '.')]\n",
            "[('To', 'TO')]\n",
            "[('do', 'VB')]\n",
            "[('this', 'DT')]\n",
            "[(',', ',')]\n",
            "[('click', 'NN')]\n",
            "[('within', 'IN')]\n",
            "[('the', 'DT')]\n",
            "[('search', 'NN')]\n",
            "[('box', 'NN')]\n",
            "[('after', 'IN')]\n",
            "[('opening', 'NN')]\n",
            "[('the', 'DT')]\n",
            "[('file', 'NN')]\n",
            "[('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAMED ENTITY RECOGNITION (NER)**"
      ],
      "metadata": {
        "id": "oBcyDmQi-07C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "from nltk import ne_chunk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYtP9tos52uq",
        "outputId": "fdb78587-1d94-41ca-8bd8-b1c60024edfd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"If you want to search for a specific word, this is quite easy. Just know that if any of your documents contain this word or phrase, then all of them will show up at once. To do this, click within the search box after opening the file.\""
      ],
      "metadata": {
        "id": "vh2gUyhM_MAx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text) #tokens\n",
        "tags = nltk.pos_tag(tokens)  #tag pos of tokens"
      ],
      "metadata": {
        "id": "gYyrG2Cj_MPz"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner = ne_chunk(tags)\n",
        "ner"
      ],
      "metadata": {
        "id": "h-3O4qZW_MVB"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}